{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Aritificial Intelligence\n",
    "School of Information, Media and Design\n",
    "Project Work: Comparison of different ML algorithms on same data set\n",
    "#### Sanketh Mysore Shivakumar\n",
    "#### 11010385"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context and Purpose \n",
    "\n",
    "This project is comprised of trainings, predictions and accuracies of various simple machine learning algorithms on data sets obtained from: https://github.com/udacity/ud120-projects.\n",
    "The motivation to work on this dataset and compare various algos rather than performing one main project is the following:\n",
    "•\tUnderstanding of ML fundamentals\n",
    "•\tPractically experiencing the Pros and Cons of each Algo.\n",
    "•\tHaving a more traditional approach to learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "#### DataSet:\n",
    "\n",
    "Over 7000 email texts from two people labelled 1 and 0 for Chris and Sara respectively. \n",
    "Objective: Given an email text, the classifier should determine whether the email was authored by Chris or Sara using Gaussian Naïve Bayes Algorithm\n",
    "\n",
    "#### Time Accuracy and Performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "training time: 2.468 s\n",
      "predicting time: 0.428 s\n",
      "Classification accuracy:  0.9732650739476678\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "\n",
    "\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "#features_train = features_train[:len(features_train)/10]\n",
    "#labels_train = labels_train[:len(labels_train)/10]\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "print \"training time:\", round(time()-t0, 3), \"s\"\n",
    "t1 = time()\n",
    "clf.predict(features_test)\n",
    "print \"predicting time:\", round(time()-t1, 3), \"s\"\n",
    "print \"Classification accuracy: \",clf.score(features_test, labels_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n",
    "#### DataSet:\n",
    "\n",
    "The same dataset is used.\n",
    "\n",
    "Objective: Given an email text, the classifier should determine whether the email was authored by Chris or Sara using SVM\n",
    "\n",
    "#### Time Accuracy and Performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "training time: 269.458 s\n",
      "predicting time: 27.684 s\n",
      "Classification accuracy:  0.9908987485779295\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "#features_train = features_train[:len(features_train)/10]\n",
    "#labels_train = labels_train[:len(labels_train)/10]\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='rbf', C=10000.)\n",
    "t0 = time()\n",
    "clf.fit(features_train,labels_train)\n",
    "print \"training time:\", round(time()-t0, 3), \"s\"\n",
    "t1 = time()\n",
    "clf.predict(features_test)\n",
    "print \"predicting time:\", round(time()-t1, 3), \"s\"\n",
    "print \"Classification accuracy: \", clf.score(features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we observe that the SVM accuracy is higher than that of Naive Bayes, making it better for text classification. (An optimal acuracy was reached when the kernel used was rbf and C value = 10000.) It seems to have taken 60 times more time for predicting as compared to GaussianNB which is a huge drawback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "\n",
    "#### DataSet:\n",
    "The same dataset is used.\n",
    "\n",
    "Objective: Given an email text, the classifier should determine whether the email was authored by Chris or Sara using a DTC\n",
    "\n",
    "#### Time Accuracy and Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "training time: 138.329 s\n",
      "predicting time: 0.069 s\n",
      "Classification accuracy:  0.9789533560864618\n"
     ]
    }
   ],
   "source": [
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "#features_train = features_train[:len(features_train)/10]\n",
    "#labels_train = labels_train[:len(labels_train)/10]\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "t0 = time()\n",
    "clf.fit(features_train,labels_train)\n",
    "print \"training time:\", round(time()-t0, 3), \"s\"\n",
    "t1 = time()\n",
    "clf.predict(features_test)\n",
    "print \"predicting time:\", round(time()-t1, 3), \"s\"\n",
    "print \"Classification accuracy: \", clf.score(features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we observe that the Decision tree accuracy is is in between SVM and Naive Bayes for this use case.  We also see that the prediction time is 22000% better than SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron\n",
    "\n",
    "#### DataSet:\n",
    "The same dataset is used.\n",
    "\n",
    "Objective: Given an email text, the classifier should determine whether the email was authored by Chris or Sara using a DTC\n",
    "\n",
    "#### Time Accuracy and Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "training time: 0.991 s\n",
      "predicting time: 0.038 s\n",
      "Classification accuracy:  0.4920364050056883\n"
     ]
    }
   ],
   "source": [
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "#features_train = features_train[:len(features_train)/10]\n",
    "#labels_train = labels_train[:len(labels_train)/10]\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "t0 = time()\n",
    "clf.fit(features_train,labels_train)\n",
    "print \"training time:\", round(time()-t0, 3), \"s\"\n",
    "t1 = time()\n",
    "clf.predict(features_test)\n",
    "print \"predicting time:\", round(time()-t1, 3), \"s\"\n",
    "print \"Classification accuracy: \", clf.score(features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we observe that the MLP accuracy is much lower, making GaussianNB or SVM better for text classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K nearest neighbours\n",
    "#### DataSet:\n",
    "\n",
    "The same dataset is used.\n",
    "\n",
    "Objective: Given an email text, the classifier should determine whether the email was authored by Chris or Sara using a DTC\n",
    "\n",
    "#### Time Accuracy and Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\d074223\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "training time: 8.421 s\n",
      "predicting time: 310.491 s\n",
      "Classification accuracy:  0.8811149032992036\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "t0 = time()\n",
    "clf.fit(features_train,labels_train)\n",
    "print \"training time:\", round(time()-t0, 3), \"s\"\n",
    "t1 = time()\n",
    "clf.predict(features_test)\n",
    "print \"predicting time:\", round(time()-t1, 3), \"s\"\n",
    "print \"Classification accuracy: \", clf.score(features_test,labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Here we observe that the K nearest neighbour algo accuracy is much lower, making GaussianNB or SVM better for text classification. The time taken also seems to be quite high hence ruling it out as an option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Comparison Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Algorithm|Training time|Predicting time|Accuracy|\n",
    "|---------|-------------|---------------|--------|\n",
    "|Naive Bayes|2.468s|0.428s|97.3265%|\n",
    "|SVM|269.458s|27.6s|99.0898%|\n",
    "|Decision Tree Classifier|138.329s|0.069s|97.8953%|\n",
    "|Multilayer Perceptron|0.991s|0.038s|49.2036%|\n",
    "|KNN|8.421s|310.491s|88.1114%|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "Since the features was a set of probabilites of words as phrases for each person, one feature was not a function of another. Hence it was not possible to show the data and in terms of a scatter plot with one variable as a function of another.\n",
    "\n",
    "Below I have tried to show the data points of 2 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0xf9dcbe0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "#features_train = features_train[:len(features_train)/10]\n",
    "#labels_train = labels_train[:len(labels_train)/10]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature1 = [] \n",
    "feature2 = [] \n",
    "for i in range(len(features_train)):\n",
    "    feature1.append(features_train[i][24])\n",
    "    feature2.append(features_train[i][65])\n",
    "\n",
    "    \n",
    "plt.scatter(feature1,feature2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### source code of supporting function\n",
    "\n",
    "The code which takes care of loading the data from a .plk file and dividing the testing and traning data can be found in this file email_preprocess.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
